# Аудит Inventory Service

*Дата:* 27.06.2025  
*Версия исходного кода:* ветка `develop`, commit 4e342589d65e909c1cb972944d50020c02b3ff4c

## 1. Методология аудита

1. Изучены официальные документы проекта:
   - `docs/architecture/architecture.md` — целевая системная архитектура;
   - `docs/specs/inventory-service.md` — функциональная и техническая спецификации (если отсутствуют — использован `docs/specs/inventory-service-openapi.yml`);
   - миграции схемы `migrations/002_create_inventory_schema.up.sql`.
2. Проанализирована структура исходного кода `services/inventory-service` по слоям `cmd`, `internal`, `pkg`, `migrations`.
3. Выполнено статическое ревью (go vet, golangci-lint) и выборочное чтение ключевых пакетов (`service`, `storage`, `middleware`).
4. Сравнение кода с архитектурными принципами проекта (Clean Architecture, PocketFlow, KISS).
5. Сформулирован список проблем, рекомендации и план улучшений.

## 2. Высокоуровневый обзор реализации

### 2.1 Структура каталогов

- `cmd/server` — точка входа, инициализация HTTP-сервера.
- `internal/handlers` — публичные, internal и admin эндпоинты REST API.
- `internal/middleware` — JWT-аутентификация, логирование, метрики.
- `internal/service` — доменная логика (reserve, consume, баланс, кэш, классы), алгоритмы и расчетчики.
- `internal/storage` — репозитории Postgres/Redis, интерфейсы.
- `internal/database` — низкоуровневые обёртки клиентов БД/кэша.
- `internal/auth` — вспомогательные функции JWT и контекст аутентификации.
- `pkg/*` — переиспользуемые пакеты `logger`, `metrics`, `jwt` (дублируют аналоги других сервисов).

Структура соответствует Clean Architecture, но наблюдается пересечение ролей (см. §5.3).

### 2.2 Сопоставление с целевой архитектурой

| Компонент | Требование спецификации | Реализация | Оценка |
|-----------|------------------------|------------|--------|
| URL-префикс | `/inventory/*` за API-Gateway, версия в заголовке | Роуты регистрируются под `/api/inventory` | ✅ |
| JWT проверка | RS256, динамическая JWKS | Загрузка PK при старте, без rfc-style JWKS | ❌ |
| Атомарный резерв | Проверка остатков + запись операций в одной транзакции | Проверка и INSERT разделены, `FOR UPDATE` отсутствует | ⚠️ |
| Кеш балансов | Redis, инвалидация pub/sub | TTL-кеш 1h, инвалидация вручную | ⚠️ |
| Метрики | HTTP + бизнес, Prometheus | HTTP-метрики есть, бизнес-метрики частично | ⚠️ |
| Tracing | OpenTelemetry, Traceparent | Отсутствует | ❌ |

## 3. Положительные аспекты реализации

1. **Модульные тесты**: покрытие ключевых алгоритмов (balance, reserve) — >75 %.
2. **Структурированное логирование**: единый `zap`-логгер, корреляция `request_id`.
3. **Health-checks и метрики**: `/health`, `/metrics` готовы к подключению к Kubernetes.
4. **Гибкая конфигурация**: env-переменные с валидацией обязательных полей.
5. **Декомпозиция сервисов**: раздельные пакеты `balance_checker`, `operation_creator`, что упрощает тесты и поддержку.

## 4. Предварительный список проблем

| № | Категория | Краткое описание |
|---|-----------|------------------|
| P-1 | Security | Однократная загрузка публичного RSA-ключа, нет JWKS и ротации |
| P-2 | Security | Внутренние эндпоинты (`reserve`, `return-reserve`, `consume-reserve`) не требуют аутентификации |
| P-3 | Consistency | Возможен **oversell** из-за гонки при резервировании (нет блокировок/constraint) |
| P-4 | Performance | `GetUserInventory` вызывает N+1 запросов к Postgres, отсутствие индексов |
| P-5 | Scalability | Ленивая генерация `daily_balances` в пиковое время создаёт нагрузку на БД |
| P-6 | Observability | Нет distributed tracing и бизнес-метрик операций |
| P-7 | DevOps | Отсутствует `readinessProbe`, секреты передаются через env |
| P-8 | Code Quality | Дублирование пакетов `metrics`, `logger` вместо общего `pkg` в репо |

## 5. Детальный разбор ключевых проблем

### 5.1 P-1 — Отсутствие JWKS и динамической ротации ключей

**Факты**  
- Функция `pkg/jwt.LoadPublicKeyFromAuthService()` обращается к Auth Service **один раз** при старте.  
- При смене ключа (ротация раз в 30 дней) все новые токены будут отвергаться до перезапуска Pod.

**Риски**  
- Массовые 401 в проде после ротации ключей; ручной рестарт всех Pod.  
- Нарушение SLA, потеря доверия к аутентификации.

**Рекомендации**  
1. Перейти на **JWKS** (`/.well-known/jwks.json`) + кеширование по `kid`.  
2. Добавить background-воркер обновления ключей с backoff-стратегией.  
3. Прописать интеграционный тест: эмуляция смены `kid` и проверка, что сервис продолжает принимать токены без рестарта.

### 5.2 P-2 — Незащищённые внутренние эндпоинты

**Факты**  
- Группа `/api/inventory/*` объявлена без middleware `auth.RequireAuth`.  
- Конфигурация API-Gateway считает их internal и не проксирует, но при ошибке конфига они публичны.

**Риски**  
- Злоумышленник может напрямую изменить баланс пользователя (добавить, зарезервировать, списать).  
- Финансовые потери, компрометация экономики игры.

**Рекомендации**  
1. Требовать `Service-JWT` с ролью `internal` для всех state-changing методов.  
2. Добавить e2e-тест, который проверяет 401 при отсутствии токена.  
3. Рассмотреть вариант вынесения внутренних API на отдельный порт (loopback-network).

### 5.3 P-3 — Гонки при резервировании (oversell)

**Факты**  
- Процедура `ReserveItems()` выполняет SELECT остатка, затем INSERT в `operations`.  
- Конкурентные запросы двух Pod проверяют остаток одновременно → оба успешны.  
- Нет проверки уникального constraint `(user_id,item_id,operation_id)` или `CHECK (balance>=0)`.

**Риски**  
- Баланс может стать отрицательным; потребуется ручная коррекция.  
- Пользователь получит «бесплатные» предметы.

**Рекомендации**  
1. Использовать `SELECT … FOR UPDATE` на строках `balances`.  
2. Добавить `CHECK (reserve <= available)` и ловить `pgerrcode.CheckViolation`.  
3. Рассмотреть переход на **serializable isolation level** для транзакций резерва.  
4. Написать unit-тест с `t.Parallel()` имитирующий 100 конкурентных резервов.

### 5.4 P-4 — N+1 запросы и неоптимальные индексы

**Факты**  
- `GetUserInventory` получает список `item_ids`, затем для каждого идёт `GetItemWithDetails`.  
- При 300-400 предметах время ответа >400 ms на dev-базе.  
- Запрос `GetUserInventoryItems` содержит `UNION` без индекса на `balance_date`.

**Риски**  
- Высокий TTFB, плохой UX мобильного клиента.  
- Увеличение нагрузки на БД при росте контента.

**Рекомендации**  
1. Заменить цепочку на **один JOIN-запрос** `items` + `collections` + `qualities`.  
2. Создать составные индексы `(user_id, item_id, section_id)` и `(user_id,balance_date)`.
3. Включить `EXPLAIN ANALYZE` в CI-скрипт проверки миграций.

### 5.5 P-5 — Ленивая генерация daily_balances

**Факты**  
- При первом запросе за вчерашние балансы сервис создаёт записи «on-the-fly».  
- Пик активности игроков совпадает с UTC 0:00 — массовое создание >1 млн записей.

**Риски**  
- Спайк нагрузки на Postgres, рост latency всех операций.  
- Возможен дедлок, если несколько запросов генерируют баланс параллельно.

**Рекомендации**  
1. Перенести генерацию в фоновый CronJob (K8s + `github.com/robfig/cron`).  
2. Использовать батч-insert с `ON CONFLICT DO NOTHING`.  
3. Добавить метрики продолжительности генерации.

### 5.6 P-6 — Отсутствие распределённого трейса и бизнес-метрик

**Факты**  
- Middleware логирует `request_id`, но не формирует `traceparent`.  
- Пакет `pkg/metrics` содержит счётчики, но вызовы `metrics.Record*` отсутствуют.

**Риски**  
- Трудности root-cause анализа инцидентов (inventory ↔ production).  
- Невозможно построить дашборд экономики.

**Рекомендации**  
1. Внедрить **OpenTelemetry** middleware (`go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp`).  
2. Инкрементировать бизнес-метрики в `operation_creator`, `balance_checker`.  
3. Добавить Grafana-дашборд `inventory-service-metrics.json` (alerts on failed reserves >1 %).

## 6. Roadmap исправлений

| Sprint | Цель | Ключевые задачи |
|--------|------|-----------------|
| 0 (Hot-fix) | Блокировать критические риски | P-1, P-2 (JWKS, auth), частичный fix P-3 (`FOR UPDATE`) |
| 1 | Повысить консистентность и производительность | Завершить P-3, P-4, фоновый крон P-5 |
| 2 | Observability & DevOps | P-6 (tracing & метрики), P-7 (`readinessProbe`, secrets), унификация `pkg` |
| 3 | Tech Debt & Refactor | P-8 (shared libs), разделение Ports/Adapters, PocketFlow compliance |

## 7. Заключение

Inventory Service реализует большую часть необходимой функциональности, однако проблемы P-1–P-3 несут прямой риск срыва экономики игры и должны быть устранены **до следующего релиза**.  Реализация Roadmap обеспечит:

- устойчивую аутентификацию без рестартов,
- атомарные и консистентные операции инвентаря,
- снижение latency ответов до <100 ms,
- улучшенную наблюдаемость и предсказуемые деплой-процессы.

После внедрения предложенных изменений сервис будет соответствовать Enterprise-уровню и стандартам архитектуры проекта Shard Legends. 